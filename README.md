# Lingala Speechâ€‘toâ€‘Text Corpus (Lingalaâ€‘STT)

A communityâ€‘driven effort to create, curate, and openly publish a highâ€‘quality Lingala speech corpus for automatic speech recognition (ASR) research and products.

---

## ğŸ“ Repository layout

```
lingala-stt/
â”œâ”€â”€ README.md                â† you are here
â”œâ”€â”€ LICENSE                  â† CCâ€‘BYâ€‘4.0
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt         â† Python deps (pysoundfile, torchaudio, whisper, pyanote, etc.)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 â† untouched downloads (radio, field recordings â€¦)
â”‚   â”œâ”€â”€ interim/             â† sliced, not yet validated
â”‚   â””â”€â”€ processed/           â† train/dev/test splits + manifests
â”œâ”€â”€ prompts/                 â† sentence prompts (.tsv) for crowd recording
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_okapi.py    â† grab daily RadioÂ Okapi bulletins
â”‚   â”œâ”€â”€ segment.py           â† silenceâ€‘based segmentation
â”‚   â”œâ”€â”€ align_whisper.py     â† autoâ€‘transcribe + forced alignment
â”‚   â”œâ”€â”€ validate_ui.py       â† launch Clipâ€‘Editor for manual validation
â”‚   â””â”€â”€Â export_hf.py         â† push processed dataset to HuggingÂ Face Hub
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ STYLE_GUIDE.md       â† transcription conventions
â”‚   â”œâ”€â”€ ROADMAP.md           â† milestones & governance
â”‚   â””â”€â”€ model_zoo.md         â† checkpoints & WER table
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â”œâ”€â”€ lint.yml         â† flake8 + black
        â””â”€â”€ validate.yml     â† CI: dataset schema + audio integrity
```

## Audio Sources
- **RadioÂ Okapi**: daily news bulletins (1â€“15Â min) from the DRCâ€™s leading radio station.
- **Crowd recordings**: short prompts (1â€“5Â s) read by volunteers across the DRC.
- **Field recordings**: spontaneous conversations and dialect samples from various regions.
- **Public domain**: any other audio clips in Lingala that are freely available.
 - **Social Media**: 
    -  'facebook_live': 'Live Lingala broadcasts',
    -  'tiktok_videos': 'Short clips with clear speech'
    -  'YouTube': 'Lingala content from YouTube channels'
---

## ğŸš€ Quickâ€‘start

```bash
# 1. clone & install
$ git clone https://github.com/yourâ€‘org/lingala-stt.git
$ cd lingala-stt
$ python -m venv .venv && source .venv/bin/activate
$ pip install -r requirements.txt

# 2. download & segment a single RadioÂ Okapi bulletin (example)
$ python scripts/download_okapi.py --date 2025-06-11  
$ python scripts/segment.py data/raw/2025â€‘06â€‘11_okapi.mp3 \
                        --out_dir data/interim/2025â€‘06â€‘11

# 3. autoâ€‘align
$ python scripts/align_whisper.py data/interim/2025â€‘06â€‘11  

# 4. manual validation UI (opens in browser)
$ python scripts/validate_ui.py

# 5. export HFâ€‘ready dataset
$ python scripts/export_hf.py --repo jeremie/lingala-stt-dev
```

---

## ğŸ¤ Contributing

1. **Check an issue** tagged `goodÂ firstÂ issue` or open a new one.
2. Follow the [STYLE\_GUIDE](docs/STYLE_GUIDE.md) when transcribing.
3. Run `pre-commit run --all-files` before pushing.
4. Submit your PRâ€”GitHub Actions will run lint + dataset integrity checks.

All contributors agree to license their work under **CCâ€‘BYâ€‘4.0**.

---

## ğŸ“œ License

```
Creative Commons Attribution 4.0 International
<https://creativecommons.org/licenses/by/4.0/>
```

---

## ğŸ› ï¸ Dataset card for the HuggingÂ FaceÂ Hub

Below is a template you can copy to `dataset_card.md` in **a *separate* HuggingÂ Face repo** (e.g. `jeremie/lingala-stt`).
Lines starting with `>` are comments to remove.

````yaml
---
language: [ "ln" ]         # ISOÂ 639â€‘1 for Lingala
license: "cc-by-4.0"
pretty_name: "Lingala Speechâ€‘toâ€‘Text Corpus v1.0"
version: "1.0.0"
author: "Lingalaâ€‘STT community"
multilinguality: monolingual
> Add more tags if you also provide French/English translations
---

# Lingala Speechâ€‘toâ€‘Text Corpus v1.0

## Summary
A 120â€‘hour validated corpus of spoken Lingala covering news broadcasts, crowdâ€‘read prompts, and conversational speech.  Each clip is 1â€“15Â seconds long, 48Â kHz WAV, with orthographic transcription in standard Lingala.

## Supported Tasks and Leaderboards
- **Automatic Speech Recognition** (primary)
- **Selfâ€‘supervised preâ€‘training** (raw split)

| Split | Hours | #Â Clips | #Â Speakers |
|-------|------:|--------:|-----------:|
| train | 102Â h | 46â€¯381 |  310 |
| dev   |  12Â h |  5â€¯468 |   90 |
| test  |   6Â h |  2â€¯601 |   82 |

## Usage example
```python
from datasets import load_dataset
ds = load_dataset("jeremie/lingala-stt", split="train")
print(ds[0]["audio"]["array"], ds[0]["text"])
````

## Citation

```
@dataset{lingala_stt_2025,
  title     = {Lingala Speechâ€‘toâ€‘Text Corpus v1.0},
  author    = {Jeremie Nlandu Mabiala and contributors},
  year      = {2025},
  publisher = {HuggingÂ Face},
  version   = {1.0},
  url       = {https://huggingface.co/datasets/jeremie/lingala-stt}
}
```

---

```

---

## ğŸ”„ How GitHub â†”ï¸ HuggingÂ Face sync works

1. **Dataset building scripts live in this GitHub repo.**
2. GitHub Action `export_hf.yml` (coming soon) runs nightly or on demand to:
   - pull latest `data/processed/` manifests,
   - upload only the diff to the HF dataset repo via `huggingface_hub` CLI,
   - trigger the HF dataset viewer refresh.
3. Model checkpoints fineâ€‘tuned on this data can then depend on the same HF dataset repo.

---

## ğŸ“… Roadmap (excerpt)

| Month | Deliverable |
|-------|-------------|
| 2025â€‘07 | v0.2 release (60Â h) + baseline WER report |
| 2025â€‘10 | Field recordings (dialects) merged |
| 2026â€‘02 | v1.0 stable + Interspeech paper prep |

<br/>

---

*Maintained by @jeremieâ€‘nlandu and the Lingalaâ€‘STT community. For questions, open an issue or ping **#lingala-asr** on the Masakhane Discord.*

```
